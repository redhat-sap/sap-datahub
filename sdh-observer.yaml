apiVersion: template.openshift.io/v1
kind: Template
metadata:
  name: sdh-observer
  annotations:
    openshift.io/display-name: "OpenShift enabler and observer for SAP Data Hub"
    description: >
      On Red Hat Enterprise Linux CoreOS, SAP Data Hub's vsystem-vrep
      statefulset needs to be patched to mount `emptyDir` volume at `/exports`
      directory in order to enable NFS exports in the container running on top
      of overlayfs which is the default filesystem in RHCOS.

      The template spawns a pod that observes the particular namespace where
      SAP Data Hub runs modifies the vsystem-vrep statefulset as soon as it
      appears to enable the NFS exports.

      The observer also allows to patch `vflow` pods to mark registry as insecure.
      Unless kaniko builds are enabled, it will also patch `vflow` pods to run as
      Super Privileged Containers in order to access Docker sockets on nodes.

      Additionally, it patches diagnostics-fluentd daemonset to allow its pods
      to access log files on the host system. On OCP 4, it also modifies it to
      parse plain text log files instead of preconfigured json.

      On Red Hat Enterprise Linux CoreOS, "vsystem-iptables" containers need to
      be run as privileged in order to load iptables-related kernel modules.
      SAP Data Hub containers named "vsystem-iptables" deployed as part of
      every "vsystem-app" deployment attempt to modify iptables rules without
      having the necessary permissions. The ideal solution is to pre-load these
      modules during node's startup. When not feasable, this template can also
      fix the permissions on-the-fly as the deployments are created.

      The template must be instantiated before the installation of SAP Data Hub.
      Also the namespace, where SAP Data Hub will be installed, must exist before
      the instantiation.

      Usage:
        If running in the same namespace as Data Hub, instantiate the template
        as is in the desired namespace:

          oc project $SDH_NAMESPACE
          oc process sdh-observer NAMESPACE=$SDH_NAMESPACE | oc create -f -

        If running in a different/new namespace/project, instantiate the
        template with parameters SDH_NAMESPACE and NAMESPACE, e.g.:

          oc new-project $SDH_NAMESPACE
          oc new-project sapdatahub-admin
          oc process sdh-observer \
              SDH_NAMESPACE=$SDH_NAMESPACE \
              NAMESPACE=sapdatahub-admin | oc create -f -

    openshift.io/provider-display-name: "Red Hat, Inc."
    openshift.io/documentation-url: "https://access.redhat.com/articles/4324391"
message: >-
  The vsystem-app observer and patcher will be started. You can watch the progress
  with the following command:

    oc logs -f dc/sdh-observer
objects:
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    name: sdh-observer
    namespace: ${NAMESPACE}
    labels:
      deploymentconfig: sdh-observer

- apiVersion: rbac.authorization.k8s.io/v1
  kind: Role
  metadata:
    name: sdh-observer
    namespace: ${SDH_NAMESPACE}
    labels:
      deploymentconfig: sdh-observer
  rules:
  - apiGroups:
    - apps
    - extensions
    resources:
    - deployments
    - deployments/scale
    - statefulsets
    - statefulsets/scale
    verbs:
    - get
    - list
    - patch
    - watch
  - apiGroups:
    - apps
    - extensions
    resources:
    - daemonsets
    verbs:
    - get
    - list
    - patch
    - update
    - watch
  - apiGroups:
    - ""
    resources:
    # necessary to get the configured registry out of secrets/installer-config
    - secrets
    verbs:
    - get
  - apiGroups:
    - ""
    resources:
    - configmaps
    verbs:
    - get
    - list
    - watch
    - patch
  - apiGroups:
    - ""
    resources:
    - pods
    verbs:
    - delete
    - get
    - list
  # mandatory permissions if running in a different namespace
  - apiGroups:
    - ""
    resources:
    - namespaces
    - namespaces/status
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    - project.openshift.io
    resources:
    - projects
    verbs:
    - get
  # necessary to cleanup obsolete sdh helpers
  - apiGroups:
    - apps
    - deploymentconfigs.apps.openshift.io
    resources:
    - deploymentconfigs
    verbs:
    - get
    - list
    - delete
  - apiGroups:
    - ""
    - authorization.openshift.io
    - rbac.authorization.k8s.io
    resources:
    - roles
    - rolebindings
    - serviceaccounts
    verbs:
    - get
    - list
    - delete

- apiVersion: rbac.authorization.k8s.io/v1
  kind: RoleBinding
  metadata:
    namespace: ${SDH_NAMESPACE}
    name: sdh-observer-${ROLE_BINDING_SUFFIX}
    labels:
      deploymentconfig: sdh-observer
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: Role
    name: sdh-observer
    namespace: ${SDH_NAMESPACE}
  subjects:
  - kind: ServiceAccount
    name: sdh-observer
    namespace: ${NAMESPACE}

- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    name: sdh-observer-2-node-reader-${ROLE_BINDING_SUFFIX}
    labels:
      deploymentconfig: sdh-observer
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: system:node-reader
  subjects:
  - kind: ServiceAccount
    name: sdh-observer
    namespace: ${NAMESPACE}

- apiVersion: v1
  kind: DeploymentConfig
  metadata:
    name: sdh-observer
    namespace: ${NAMESPACE}
    labels:
      deploymentconfig: sdh-observer
  spec:
    selector:
      deploymentconfig: sdh-observer
    replicas: 1
    strategy:
      type: Rolling
    triggers:
    - type: "ConfigChange"
    template:
      metadata:
        labels:
          deploymentconfig: sdh-observer
          target: "vsystem-app.datahub.sap.com"
      spec:
        containers:
        - env:
          - name: SDH_NAMESPACE
            value: ${SDH_NAMESPACE}
          - name: DRY_RUN
            value: ${DRY_RUN}
          - name: REGISTRY
            value: ${REGISTRY}
          - name: MARK_REGISTRY_INSECURE
            value: ${MARK_REGISTRY_INSECURE}
          - name: MAKE_VSYSTEM_IPTABLES_PODS_PRIVILEGED
            value: ${MAKE_VSYSTEM_IPTABLES_PODS_PRIVILEGED}
          - name: NODE_LOG_FORMAT
            value: ${NODE_LOG_FORMAT}
          image: "${BASE_IMAGE}:${BASE_IMAGE_TAG}"
          name: sdh-observer
          command:
          - /bin/bash
          args:
          - "-c"
          - |
            set -euo pipefail
            IFS=$'\n\t'
            function join() { local IFS="$1"; shift; echo "$*"; }
            if [[ -n "${SDH_NAMESPACE:-}" ]]; then
              export HOME="$(mktemp -d)"  # so that oc can create $HOME/.kube/ directory
              oc project "$SDH_NAMESPACE"
            else
              SDH_NAMESPACE="$(oc project -q 2>/dev/null|| :)"
            fi
            # support both 3.x and 4.x output formats
            version="$(oc version --short 2>/dev/null || oc version)"
            serverVersion="$(sed -n 's/^\([sS]erver.*:\|[oO]pen[sS]hift\) v\([0-9]\+\.[0-9]\+\).*/\2/p' \
                              <<<"$version" | head -n 1)"
            clientVersion="$(sed -n 's/^\([cC]lient.*:\|oc\) v\([0-9]\+\.[0-9]\+\).*/\2/p' \
                              <<<"$version" | head -n 1)"
            # translate k8s 1.13 to ocp 4.1
            if [[ "${serverVersion:-}" =~ ^1\.([0-9]+)$ && "${BASH_REMATCH[1]}" -gt 12 ]]; then
              serverVersion="4.$((${BASH_REMATCH[1]} - 12))"
            fi
            if [[ -z "${clientVersion:-}" ]]; then
              printf 'WARNING: Failed to determine oc client version!\n' >&2
            elif [[ "${serverVersion}" != "${clientVersion}" ]]; then
              printf 'WARNING: Client version != Server version (%s != %s).\n' "$clientVersion" "$serverVersion" >&2
              printf '         Please reinstantiate this template with the correct BASE_IMAGE_TAG parameter (e.g. v%s)."\n' >&2 \
                "$serverVersion"
            fi

            if [[ ! "${NODE_LOG_FORMAT:-}" =~ ^(text|json|)$ ]]; then
              printf 'WARNING: unrecognized NODE_LOG_FORMAT; "%s" is not one of "json" or "text"!' \
                "$NODE_LOG_FORMAT"
              exit 1
            fi
            if [[ -z "${NODE_LOG_FORMAT:-}" ]]; then
              if [[ "${serverVersion}" =~ ^3 ]]; then
                NODE_LOG_FORMAT=json
              else
                NODE_LOG_FORMAT=text
              fi
            fi

            function log() {
              date -R | tr '\n' ' ' >&2
              # no new line
              if [[ "$1" == -n ]]; then
                shift
              elif [[ "${1: -1}" != $'\n' ]]; then
                local fmt="${1:-}\n"
                shift
                printf "$fmt" "$@" >&2
                return 0
              fi
              printf "$@" >&2
            }

            registry="${REGISTRY:-}"
            function get_registry() {
              if [[ -z "${registry:-}" ]]; then
                registry="$(oc get secret -o go-template='{{index .data "installer-config.yaml"}}' installer-config | \
                   base64 -d | sed -n 's/^\s*\(DOCKER\|VFLOW\)_REGISTRY:\s*\(...\+\)/\2/p' | \
                    tr -d '"'"'" | grep -v '^[[:space:]]*$' | tail -n 1)"
              fi
              if [[ -z "${registry:-}" ]]; then
                log "Failed to determine the registry!"
                return 1
              fi
              printf '%s\n' "$registry"
            }

            function terminate() {
              # terminate all the process in the container once one observer dies
              kill -9 -- `ps -ahx | awk '{print $1}' | grep -v -F "$BASHPID" | tac`
            }

            function observe() {
              oc observe --listen-addr=:11254 configmap   &
              oc observe --listen-addr=:11253 daemonset   &
              oc observe --listen-addr=:11252 statefulset &
              oc observe --listen-addr=:11251 deploy      &
              while true; do
                sleep 0.1
                if [[ "$(jobs -r | wc -l)" -lt 3 ]]; then
                  terminate
                fi
              done
            }

            function evalBool() {
              local varName="$1"
              local default="${2:-}"
              eval 'local value="${'"$varName"':-}"'
              if [[ -z "${value:-}" ]]; then
                value="${default:-}"
              fi
              grep -q -i '^\s*\(y\(es\)\?\|true\|1\)\s*$' <<<"${value:-}"
            }

            function runOrLog() {
              if evalBool DRY_RUN; then
                echo "$@"
              else
                "$@"
              fi
            }

            gotmplarr=(
              '{{range $di, $d := .items}}'
                '{{if eq .kind "Deployment"}}'
                  '{{with $appcomp := index .metadata.labels "datahub.sap.com/app-component"}}'
                    '{{if eq $appcomp "vsystem-app"}}'
                      # vsystem-app deployment
                      '{{range $i, $c := $d.spec.template.spec.containers}}'
                        '{{if eq .name "vsystem-iptables"}}'
                          # print (string kind)/(string sdh-app-component):(string "ready" or "unready"):(int containerIndex):(bool unprivileged)
                          '{{$d.kind}}/{{$appcomp}}:'
                          '{{with $s := $d.status}}'
                            '{{with $s.replicas}}'
                              '{{with $s.availableReplicas}}'
                                '{{if and (eq $s.replicas .) (and (gt . 0.1) (eq . $s.readyReplicas))}}'
                                  'ready'
                                '{{else}}'
                                  'unready'
                                '{{end}}'
                              # when .status.availableReplicas is undefined
                              '{{else}}'
                                'unready'
                              '{{end}}'
                            # when .status.replicas is undefined
                            '{{else}}'
                              'unready'
                            '{{end}}'
                          '{{end}}'
                         $':{{$i}}:{{not $c.securityContext.privileged}}\n'
                        '{{end}}'
                      '{{end}}'
                    '{{else if eq $appcomp "vflow"}}'
                      # print (string kind)/(string name):(string version):(bool unprivileged):[(string docker-socket-volume-mount-name):(string seLinuxtype)]
                      '{{$d.kind}}/{{$appcomp}}:'
                      '{{index $d.metadata.labels "datahub.sap.com/package-version"}}:'
                      '{{with $spec := $d.spec.template.spec}}'
                        '{{not (index $spec.containers 0).securityContext.privileged}}:'
                        '{{range $i, $vol := $spec.volumes}}'
                          '{{with $path := $vol.hostPath.path}}'
                            '{{if eq $path "/var/run/docker.sock"}}'
                              '{{$vol.name}}:'
                              '{{with $t := $spec.securityContext.seLinuxOptions.type}}{{$t}}{{end}}'
                            '{{end}}'
                          '{{end}}'
                        '{{end}}'
                      '{{end}}'
                     $'\n'
                    '{{end}}'
                  '{{end}}'
                '{{else if eq .kind "DaemonSet"}}'
                  '{{if eq .metadata.name "diagnostics-fluentd"}}'
                    # print (string kind):(int containerIndex):(string containerName):(bool unprivileged)
                    #      :(int volumeindex):(string varlibdockercontainers volumehostpath)
                    #      :(int volumeMount index):(string varlibdockercontainers volumeMount path)
                    '{{.kind}}'
                    '{{range $i, $c := $d.spec.template.spec.containers}}'
                      '{{if eq $c.name "diagnostics-fluentd"}}'
                        ':{{$i}}:{{$c.name}}:{{not $c.securityContext.privileged}}'
                        '{{range $j, $v := $d.spec.template.spec.volumes}}'
                          '{{if eq $v.name "varlibdockercontainers"}}'
                            ':{{$j}}:{{$v.hostPath.path}}'
                          '{{end}}'
                        '{{end}}'
                        '{{range $j, $vm := $c.volumeMounts}}'
                          '{{if eq $vm.name "varlibdockercontainers"}}'
                            ':{{$j}}:{{$vm.mountPath}}'
                          '{{end}}'
                        '{{end}}'
                      '{{end}}'
                    '{{end}}'
                   $'\n'
                  '{{end}}'
                '{{else if eq .kind "ConfigMap"}}'
                  '{{if eq .metadata.name "diagnostics-fluentd-settings"}}'
                    # print (string kind)/(string name)
                    $'{{.kind}}/{{.metadata.name}}\n'
                  '{{end}}'
                '{{else}}'
                  # vsystem-vrep statefulset
                  '{{if eq .metadata.name "vsystem-vrep"}}'
                    # print (string kind):(int containerIndex):(string volumeMountName)
                    '{{.kind}}'
                    '{{range $i, $c := $d.spec.template.spec.containers}}'
                      '{{if eq $c.name "vsystem-vrep"}}'
                        ':{{$i}}'
                        '{{range $vmi, $vm := $c.volumeMounts}}'
                          '{{if eq $vm.mountPath "/exports"}}'
                            ':{{$vm.name}}'
                          '{{end}}'
                        '{{end}}'
                      '{{end}}'
                    '{{end}}'
                   $'\n'
                  '{{end}}'
                '{{end}}'
              '{{end}}'
            )
            lackingPermissions=0
            for perm in get/nodes get/projects get/pods get/secrets get/configmaps \
                      watch/deployments get/deployments watch/statefulsets get/statefulsets watch/configmaps \
                      patch/deployments patch/statefulsets patch/daemonsets patch/configmaps \
                      update/daemonsets delete/pods;
            do
              if ! oc auth can-i "${perm%%/*}" "${perm##*/}" >/dev/null; then
                log -n 'Cannot "%s" "%s", please grant the needed permissions' "${perm%%/*}" "${perm##*/}"
                log ' to sdh-observer service account!'
                lackingPermissions=1
              fi
            done
            [[ "${lackingPermissions:-0}" == 1 ]] && terminate
            if [[ -n "${SDH_NAMESPACE:-}" ]]; then
              log 'Watching namespace "%s" for vsystem-apps deployments...' "$SDH_NAMESPACE"
            fi

            # delete obsolete deploymentconfigs
            ( oc get -o name {deploymentconfig,serviceaccount,role}/{vflow,vsystem}-observer 2>/dev/null;
              oc get -o name rolebinding -l deploymentconfig=vflow-observer 2>/dev/null;
              oc get -o name rolebinding -l deploymentconfig=vsystem-observer 2>/dev/null; ) | \
                xargs -r oc delete || :

            gotmpl="$(printf '%s' "${gotmplarr[@]}")"
            gotmplvflow=$'{{range $index, $arg := (index (index .spec.template.spec.containers 0) "args")}}{{$arg}}\n{{end}}'
            mkiptabsprivileged=0
            if evalBool "MAKE_VSYSTEM_IPTABLES_PODS_PRIVILEGED"; then
              mkiptabsprivileged=1
            fi

            while IFS=' ' read -u 4 -r _ _ _ _ _ name; do
              [[ -z "${name:-}" ]] && continue
              while IFS=: read -u 3 -r resource rest; do
                if [[ "${serverVersion}" =~ ^3\. && "$mkiptabsprivileged/${resource,,}" =~ ^0/(deployment/vsystem-app|statefulset) ]]; then
                  resource="${resource%%/*}"
                  log 'No need to patch vsystem pods on OpenShift %s, skipping %s/%s...' "${serverVersion}" "${resource,,}" "$name"
                  continue
                fi
                case "${resource,,}" in
                deployment/vsystem-app)
                  if [[ "${mkiptabsprivileged}" == 0 ]]; then
                    continue
                  fi
                  IFS=: read -r ready index unprivileged <<<"${rest:-}"
                  if [[ "$unprivileged" == "true" ]]; then
                    log 'Patching container #%d in deployment/%s to make its pods privileged ...' \
                        "$index" "$name" >&2
                    runOrLog oc patch "deploy/$name" --type json -p '[{
                      "op": "add",
                      "path": "/spec/template/spec/containers/'"$index"'/securityContext/privileged",
                      "value": true
                    }]'
                  else
                    log 'Container #%d in deployment/%s already patched, skipping ...' "$index" "$name"
                  fi
                  ;;

                deployment/vflow)
                  patches=()
                  IFS=: read -r pkgversion unprivileged volName seType <<<"${rest:-}"
                  pkgversion="${pkgversion#v}"
                  pkgmajor="${pkgversion%%.*}"
                  pkgminor="${pkgversion#*.}"
                  pkgminor="${pkgminor%%.*}"

                  # -insecure-registry flag is supported starting from 2.5; earlier releases need no patching
                  if evalBool MARK_REGISTRY_INSECURE && [[ -n "$(get_registry)" ]] && [[ "${pkgmajor:-0}" == 2 && "${pkgminor:-0}" -ge 5 ]]; then
                    registry="$(get_registry)"
                    readarray -t vflowargs <<<"$(oc get deploy -o go-template="${gotmplvflow}" "$name")"
                    if ! grep -q -F -- "-insecure-registry=${registry}" <<<"${vflowargs[@]}"; then
                      vflowargs+=( "-insecure-registry=${registry}" )
                      newargs=( )
                      for ((i=0; i<"${#vflowargs[@]}"; i++)) do
                        # escape double qoutes of each argument and surround it with double quotes
                        newargs+=( '"'"$(sed 's/"/\\"/g' <<<"${vflowargs[$i]}")"'"' )
                      done
                      # turn the argument array into a json list of strings
                      newarglist="[$(join , "${newargs[@]}")]"
                      log 'Patching deployment/%s to treat %s registry as insecure ...' "$name" "$registry"
                      patches+=( '{"op":"add","path":"/spec/template/spec/containers/0/args","value":'"$newarglist"'}' )
                    else
                      log 'deployment/%s already patched to treat %s registry as insecure, not patching ...' "$name" "$registry"
                    fi
                  fi

                  if [[ -n "${volName:-}" ]]; then
                    if [[ "${pkgmajor:-0}" == 2 && "${pkgminor:-0}" -ge 5 ]]; then
                      if [[ "${seType:-}" != "spc_t" ]]; then
                        log 'Patching deployment/%s to run as spc_t SELinux type ...' "$name"
                        patches+=( "$(join , \
                                    '{"op":"add"' \
                                     '"path":"/spec/template/spec/securityContext"' \
                                     '"value":{"seLinuxOptions":{"type":"spc_t"}}}' )" )
                      else
                        log 'deployment/%s already patched to run as spc_t type, not patching ...' "$name"
                      fi
                    else
                      # SDH 2.4 fails to run as spc_t on top of NFS - therefor privileged
                      if [[ "${unprivileged:-true}" != "false" ]]; then
                        log 'Patching deployment/%s to run as privileged ...' "$name"
                        patches+=( '{"op": "add"' \
                                    '"path": "/spec/template/spec/containers/0/securityContext"' \
                                    '"value": {"privileged": true}}' )
                      else
                        log 'deployment/%s already patched to run as privileged type, not patching ...' "$name"
                      fi
                    fi
                  fi

                  [[ "${#patches[@]}" == 0 ]] && continue
                  runOrLog oc patch --type json -p "[$(join , "${patches[@]}")]" deploy "$name"
                  ;;

                configmap/diagnostics-fluentd-settings)
                  contents="$(oc get "${resource,,}" -o go-template='{{index .data "fluent.conf"}}')"
                  if [[ -z "${contents:-}" ]]; then
                    log "Failed to get contents of fluent.conf configuration file!"
                    continue
                  fi
                  currentLogParseType="$(sed -n '/<parse>/,/<\/parse>/s,^\s\+@type\s*\([^[:space:]]\+\).*,\1,p' <<<"${contents}")"
                  if [[ -z "${currentLogParseType:-}" ]]; then
                    log "Failed to determine the current log type parsing of fluentd pods!"
                    continue
                  fi
                  case "${currentLogParseType}" in
                  "multi_format") continue; ;; # shall support both json and text 
                  "json")
                    if [[ "$NODE_LOG_FORMAT" == json ]]; then
                      log "Fluentd pods are already configured to parse json, not patching..."
                      continue
                    fi
                    ;;
                  "regexp")
                    if [[ "$NODE_LOG_FORMAT" == text ]]; then
                      log "Fluentd pods are already configured to parse text, not patching..."
                      continue
                    fi
                    ;;
                  esac
                  exprs=(
                    -e '/^\s\+expression\s\+\/\^.*logtag/d'
                  )
                  if [[ "$NODE_LOG_FORMAT" == text ]]; then
                    exprs+=(
                          -e '/<parse>/,/<\/parse>/s,@type.*,@type regexp,'
                          -e '/<parse>/,/<\/parse>/s,\(\s*\)@type.*,\0\n\1expression /^(?<time>.+) (?<stream>stdout|stderr)( (?<logtag>.))? (?<log>.*)$/,'
                          -e "/<parse>/,/<\/parse>/s,time_format.*,time_format '%Y-%m-%dT%H:%M:%S.%N%:z',"
                    )
                  else
                    exprs+=(
                      -e '/<parse>/,/<\/parse>/s,@type.*,@type json,'
                      -e "/<parse>/,/<\/parse>/s,time_format.*,time_format '%Y-%m-%dT%H:%M:%S.%NZ',"
                    )
                  fi
                  newContents="$(printf '%s\n' "${contents}" | sed "${exprs[@]}")"
                  log 'Patching configmap %s to support %s logging format on OCP 4...' "$name" "$NODE_LOG_FORMAT"
                  yamlPatch="$(printf '%s\n' "data:" "  fluent.conf: |" "$(sed 's/^/    /' <<<"${newContents}")")"
                  runOrLog oc patch "${resource,,}" -p "$yamlPatch"
                  readarray -t pods <<<"$(oc get pods -l datahub.sap.com/app-component=fluentd -o name)"
                  [[ "${#pods[@]}" == 0 ]] && continue
                  log 'Restarting fluentd pods ...'
                  runOrLog oc delete --force --grace-period=0 "${pods[@]}"
                  ;;

                daemonset)
                  IFS=: read -r index cname unprivileged volumeIndex hostPath volumeMountIndex mountPath <<<"${rest:-}"
                  name="diagnostics-fluentd"
                  patches=()
                  patchTypes=()
                  if [[ "$unprivileged" == "true" ]]; then
                    log 'Patching container #%d in daemonset/%s to make its pods privileged ...' \
                        "$index" "$name"
                        patches+=( "$(join ' ' '{"spec":{"template":{"spec":{"containers":' \
                                      '[{"name":"diagnostics-fluentd", "securityContext":{"privileged": true}}]}}}}')"
                        )
                        patchTypes+=( strategic )
                  else
                    log 'Container #%d in daemonset/%s already patched, skipping ...' "$index" "$name"
                  fi
                  if [[ -n "${hostPath:-}" && "${hostPath}" != "/var/lib/docker" ]]; then
                    log 'Patching container #%d in daemonset/%s to mount /var/lib/docker instead of %s' \
                        "$index" "$name" "$hostPath"
                    patches+=( "$(join ' ' '[{"op": "replace", "path":' \
                              '"/spec/template/spec/containers/'"$index/volumeMounts/$volumeMountIndex"'",' \
                          '"value": {"name":"varlibdockercontainers","mountPath":"/var/lib/docker","readOnly": true}}]' )"
                    )
                    patchTypes+=( json )
                    patches+=( "$(join ' ' '{"spec":{"template":{"spec":' \
                            '{"volumes":[{"name": "varlibdockercontainers", "hostPath":' \
                              '{"path": "/var/lib/docker", "type":""}}]}}}}' )"
                    )
                    patchTypes+=( strategic )
                  elif [[ -z "${hostPath:-}" ]]; then
                    log 'Failed to determine hostPath for varlibcontainers volume!'
                  else
                    log 'Daemonset/%s already patched to mount /var/lib/docker, skipping ...' "$name"
                  fi

                  [[ "${#patches[@]}" == 0 ]] && continue
                  dsSpec="$(oc get -o json daemonset/"$name")"
                  for ((i=0; i < "${#patches[@]}"; i++)); do
                    patch="${patches[$i]}"
                    patchType="${patchTypes[$i]}"
                    dsSpec="$(oc patch -o json --local -f - --type "$patchType" -p "${patch}" <<<"${dsSpec}")"
                  done
                  oc replace -f - <<<"${dsSpec}"
                  ;;

                statefulset)
                  IFS=: read -r index ready <<<"${rest:-}"
                  if [[ -n "${index:-}" && -n "${ready:-}" ]]; then
                    log 'statefulset/vsystem-vrep already patched, skipping ...'
                  else
                    log 'Adding emptyDir volume to statefulset/vsystem-vrep ...'
                    runOrLog oc patch "statefulset/vsystem-vrep" --type json -p '[{
                      "op": "add",
                      "path": "/spec/template/spec/containers/'"$index"'/volumeMounts/0",
                      "value": {"mountPath": "/exports", "name": "exports-volume"}
                    }, {
                      "op": "add",
                      "path": "/spec/template/spec/volumes/0",
                      "value": {"emptyDir": {}, "name": "exports-volume"}
                    }]'
                  fi
                  ;;
                esac
              done 3< <(oc get deploy/"$name" statefulset/"$name" daemonset/"$name" \
                    configmap/"$name" -o go-template="${gotmpl}" 2>/dev/null ||: )
            done 4< <(observe)
        restartPolicy: Always
        serviceAccount: sdh-observer
        serviceAccountName: sdh-observer

parameters:
  - name: BASE_IMAGE
    required: true
    value: quay.io/openshift/origin-cli
    description: >
      Base image containing the command line utilities suitable for interaction
      with the OpenShift cluster. It must contain at least oc and bash
      binaries.
  - name: BASE_IMAGE_TAG
    description: >
      The tag of BASE_IMAGE to pull. The tag shall correspond to the OpenShift release of the cluster.
    required: true
    value: "4.1"
  - name: DRY_RUN
    description: >
      If set to true, no action will be performed. The pod will just print what would have been
      executed.
    required: false
    value: "false"
  - name: SDH_NAMESPACE
    description: >
      The name of the SAP Data Hub namespace to manage. Defaults to the current
      one. It must be set only in case the observer is running in a differnt
      namespace (see NAMESPACE).
  - name: NAMESPACE
    description: >
      The desired namespace, where the vsystem-app observer shall run. Defaults to
      the current one. Needs to be set only if running the observer outside of
      SDH_NAMESPACE.
    required: true
  - name: ROLE_BINDING_SUFFIX
    description: >
      A random suffix for the new RoleBinding's name. No need to edit.
    generate: expression
    from: '[a-z0-9]{5}'
  - name: MARK_REGISTRY_INSECURE
    description: >
      Set to true if the given or configured VFLOW_REGISTRY shall be marked as insecure
      in all instances of Pipeline Modeler.
    required: true
    value: "false"
  - name: MAKE_VSYSTEM_IPTABLES_PODS_PRIVILEGED
    description: >
      Patch deployments with vsystem-iptables container to make them privileged
      in order to load kernel modules they need. Unless true, it is assumed
      that the modules have been pre-loaded on the worker nodes.
      This will make also vsystem-vrep-* pod privileged.
    required: true
    value: "false"
  - name: NODE_LOG_FORMAT
    description: >
      Format of the logging files on the nodes. Allowed values are "json" and "text".
      If not given, the default is "json" for OpenShift 3 cluster and "text" for OpenShift 4.
      By default, the SDH fluentd pods are configured to parse "json".
    required: false
  - name: REGISTRY
    description: >
      The registry to mark as insecure. If not given, it will be determined from
      the installer-config secret in the SDH_NAMESPACE.
